{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7108313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25720901RT.txt']\n"
     ]
    }
   ],
   "source": [
    "from data_loader import GliderDataLoader, GulfStreamLoader, MPADataLoader\n",
    "\n",
    "# Always fetches full list of available RT.txt files\n",
    "loader = GliderDataLoader(filenames=['25720901RT.txt'],include_qc=False)\n",
    "\n",
    "# You can inspect all available filenames\n",
    "# print(loader.get_available_files())\n",
    "\n",
    "# Load the most recent file (automatically done if no filename provided)\n",
    "df_latest = loader.load_data()\n",
    "\n",
    "# SN209 = df_latest[loader.file_list[1]]\n",
    "\n",
    "print(loader.file_list)\n",
    "\n",
    "# # Load specific file(s)\n",
    "# loader = DataLoader(filenames=[\"SPL123_RT.txt\", \"SPL124_RT.txt\"])\n",
    "# dfs = loader.load_data()  # dict of DataFrames\n",
    "gs = GulfStreamLoader()\n",
    "coords = gs.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8f338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import GliderDataLoader\n",
    "\n",
    "load = GliderDataLoader('25820301RT.txt')\n",
    "df = load.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform filter: 686 points after filtering\n",
      "Layer filter: 686 points after filtering\n",
      "Time filter: 412 points in last 24 hours\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m      9\u001b[0m fig, metadata \u001b[38;5;241m=\u001b[39m create_spatial_interpolation(\n\u001b[0;32m     10\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m     11\u001b[0m     parameter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrhodamine\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     layer_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLD\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\basedatatypes.py:3414\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3381\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3382\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3383\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3410\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m   3411\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3412\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m-> 3414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\io\\_renderers.py:425\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    422\u001b[0m     )\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    429\u001b[0m display_jupyter_version_warnings()\n\u001b[0;32m    431\u001b[0m ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "from data_loader import GliderDataLoader, GulfStreamLoader, MPADataLoader, MapDataLoader\n",
    "from nessie_interpolation_function import create_spatial_interpolation\n",
    "import datetime\n",
    "\n",
    "loader = MapDataLoader()\n",
    "df = loader.load_data()\n",
    "\n",
    "\n",
    "fig, metadata = create_spatial_interpolation(\n",
    "    df, \n",
    "    parameter='rhodamine', \n",
    "    hours_back=24, \n",
    "    platform_filter=None, \n",
    "    layer_filter=None, \n",
    "    grid_resolution=80, \n",
    "    method='linear',\n",
    "    include_map_overlay=True  # �� New parameter!\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156f3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import gomofsdataloader\n",
    "\n",
    "loader = gomofsdataloader()\n",
    "df = loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946c6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def range_slider_marks(df, target_mark_count=10):\n",
    "    \"\"\"\n",
    "    Generate a marks dictionary for a Dash RangeSlider using ~target_mark_count evenly spaced labels.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must contain 'Datetime' and 'UnixTimestamp' columns.\n",
    "    target_mark_count : int\n",
    "        Desired number of marks on the slider.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of {UnixTimestamp: formatted datetime string}\n",
    "    \"\"\"\n",
    "    # Make sure we work with sorted data\n",
    "    df = df.sort_values(\"Datetime\")\n",
    "\n",
    "    unix_min = df[\"UnixTimestamp\"].min()\n",
    "    unix_max = df[\"UnixTimestamp\"].max()\n",
    "    unix_range = unix_max - unix_min\n",
    "\n",
    "    if unix_range <= 0:\n",
    "        return {}\n",
    "\n",
    "    # Compute interval between marks (in seconds)\n",
    "    interval_seconds = unix_range // target_mark_count\n",
    "\n",
    "    # Create a list of evenly spaced timestamps\n",
    "    marks = {}\n",
    "    for t in range(int(unix_min), int(unix_max) + 1, int(interval_seconds)):\n",
    "        dt = pd.to_datetime(t, unit='s')\n",
    "        marks[t] = dt.strftime('%m/%d %H:%M')\n",
    "\n",
    "    return marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba68593",
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = range_slider_marks(df_latest, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4fff33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_first_10_pH_average(df_latest):\n",
    "    df_MLD_average = df_latest.drop_duplicates(subset=['Station', 'Cruise'], keep='first').copy()\n",
    "\n",
    "    # Initialize new columns\n",
    "    df_MLD_average['pHinsitu[Total]'] = np.nan\n",
    "    df_MLD_average['Chl_a[mg/m^3]'] = np.nan\n",
    "\n",
    "    # Group by both Station and Cruise\n",
    "    for (station, cruise), group in df_latest.groupby(['Station', 'Cruise']):\n",
    "        first_10 = group.head(5)\n",
    "        \n",
    "        if 'pHinsitu[Total]' in first_10.columns:\n",
    "            avg_pH = first_10['pHinsitu[Total]'].mean()\n",
    "            avg_chl = first_10['Chl_a[mg/m^3]'].mean()\n",
    "            \n",
    "            # Add directly to DataFrame using both Station and Cruise\n",
    "            mask = (df_MLD_average['Station'] == station) & (df_MLD_average['Cruise'] == cruise)\n",
    "            df_MLD_average.loc[mask, 'pHinsitu[Total]'] = avg_pH\n",
    "            df_MLD_average.loc[mask, 'Chl_a[mg/m^3]'] = avg_chl\n",
    "\n",
    "    # Keep only the columns you want\n",
    "    df_MLD_average = df_MLD_average[['Station', 'Cruise', 'Lat [°N]', 'Lon [°E]', 'pHinsitu[Total]', 'Chl_a[mg/m^3]']]\n",
    "\n",
    "    return df_MLD_average\n",
    "\n",
    "df_map = get_first_10_pH_average(df_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ed2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_filter = df_map[df_map[\"Cruise\"].astype(str).str.contains(\"209\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9304326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLDaverage(df_latest):\n",
    "    # Remove rows where Depth[m] or Sigma_theta[kg/m^3] is NaN\n",
    "    df_clean = df_latest.dropna(subset=['Depth[m]', 'Sigma_theta[kg/m^3]'])\n",
    "    \n",
    "    # For each station, find the row where Depth[m] is closest to 0\n",
    "    idx = df_clean.groupby('Station')['Depth[m]'].apply(lambda x: (x.abs()).idxmin())\n",
    "    \n",
    "    # Get the corresponding values\n",
    "    df_surface = df_clean.loc[idx, ['Station', 'Depth[m]', 'Sigma_theta[kg/m^3]']].reset_index(drop=True)\n",
    "    \n",
    "    return df_surface\n",
    "\n",
    "df_MLD_average = MLDaverage(df_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff67021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def get_surface_to_mld_pH_average(df_latest):\n",
    "    # Step 1: Get surface sigma values\n",
    "    df_clean = df_latest.dropna(subset=['Depth[m]', 'Sigma_theta[kg/m^3]'])\n",
    "    surface_idx = df_clean.groupby('Station')['Depth[m]'].apply(lambda x: (x.abs()).idxmin())\n",
    "    df_surface = df_clean.loc[surface_idx, ['Station', 'Depth[m]', 'Sigma_theta[kg/m^3]']].set_index('Station')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Step 2: For each station, find MLD depth and calculate pH averages\n",
    "    for station in df_surface.index:\n",
    "        station_data = df_clean[df_clean['Station'] == station].copy()\n",
    "        surface_sigma = df_surface.loc[station, 'Sigma_theta[kg/m^3]']\n",
    "        surface_depth = df_surface.loc[station, 'Depth[m]']\n",
    "        \n",
    "        # Find where sigma is 0.03 greater than surface\n",
    "        target_sigma = surface_sigma + 0.03\n",
    "        \n",
    "        # Sort by depth to ensure we're going from surface downward\n",
    "        station_data = station_data.sort_values('Depth[m]')\n",
    "        \n",
    "        # Find first depth where sigma >= target_sigma\n",
    "        mld_candidates = station_data[station_data['Sigma_theta[kg/m^3]'] >= target_sigma]\n",
    "        \n",
    "        if not mld_candidates.empty:\n",
    "            mld_depth = mld_candidates.iloc[0]['Depth[m]']\n",
    "            \n",
    "            # Get all data between surface and MLD depth\n",
    "            mask = (station_data['Depth[m]'] >= surface_depth) & (station_data['Depth[m]'] <= mld_depth)\n",
    "            layer_data = station_data[mask]\n",
    "            \n",
    "            if not layer_data.empty:\n",
    "                # Calculate pH average only\n",
    "                if 'pHinsitu[Total]' in layer_data.columns:\n",
    "                    avg_pH = layer_data['pHinsitu[Total]'].mean()\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Station': station,\n",
    "                        'Surface_Depth': surface_depth,\n",
    "                        'MLD_Depth': mld_depth,\n",
    "                        'Surface_Sigma': surface_sigma,\n",
    "                        'MLD_Sigma': target_sigma,\n",
    "                        'Layer_Thickness': mld_depth - surface_depth,\n",
    "                        'Avg_pHinsitu[Total]': avg_pH\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Usage\n",
    "df_pH_mld_averages = get_surface_to_mld_pH_average(df_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_10_pH_average(df_latest):\n",
    "    df_MLD_average = df_latest.drop_duplicates(subset=['Station'], keep='first').copy()\n",
    "\n",
    "    # Initialize new columns\n",
    "    df_MLD_average['pHinsitu[Total]'] = np.nan\n",
    "    df_MLD_average['Chl_a[mg/m^3]'] = np.nan\n",
    "\n",
    "    for station in df_latest['Station'].unique():\n",
    "        station_data = df_latest[df_latest['Station'] == station]\n",
    "        first_10 = station_data.head(5)\n",
    "        \n",
    "        if 'pHinsitu[Total]' in first_10.columns:\n",
    "            avg_pH = first_10['pHinsitu[Total]'].mean()\n",
    "            avg_chl = first_10['Chl_a[mg/m^3]'].mean()\n",
    "            \n",
    "            # Add directly to DataFrame\n",
    "            mask = df_MLD_average['Station'] == station\n",
    "            df_MLD_average.loc[mask, 'pHinsitu[Total]'] = avg_pH\n",
    "            df_MLD_average.loc[mask, 'Chl_a[mg/m^3]'] = avg_chl\n",
    "\n",
    "    # Keep only the columns you want\n",
    "    df_MLD_average = df_MLD_average[['Station', 'Lat [°N]', 'Lon [°E]', 'Avg_pHinsitu[Total]', 'Avg_Chl_a[mg/m^3]']]\n",
    "\n",
    "    return df_MLD_average\n",
    "\n",
    "# Usage\n",
    "df_averages = get_first_10_pH_average(df_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdefe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_latest.dropna(subset=['Depth[m]', 'Sigma_theta[kg/m^3]'])\n",
    "surface_idx = df_clean.groupby('Station')['Depth[m]'].apply(lambda x: (x.abs()).idxmin())\n",
    "df_surface = df_clean.loc[surface_idx, ['Station', 'Depth[m]', 'Sigma_theta[kg/m^3]']].set_index('Station')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
