{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection parameters (replace with your own Render database details)\n",
    "host = \"dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com\"  # Use your Render PostgreSQL hostname\n",
    "database = \"spraydabase\"\n",
    "user = \"spraydabase_user\"\n",
    "password = \"8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ\"\n",
    "port = 5432\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(dbname=database, user=user, password=password, host=host, port=port)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table if it doesn't exist\n",
    "cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS oceanographic_data;\n",
    "               \n",
    "    CREATE TABLE oceanographic_data (\n",
    "        Cruise VARCHAR,\n",
    "        Station INT,\n",
    "        Type VARCHAR(1),\n",
    "        Date VARCHAR,\n",
    "        Time VARCHAR,\n",
    "        Datetime VARCHAR,\n",
    "        Lon FLOAT,\n",
    "        Lat FLOAT,\n",
    "        QF_1 FLOAT,\n",
    "        Pressure FLOAT,\n",
    "        QF_2 FLOAT,\n",
    "        Temperature FLOAT,\n",
    "        QF_3 FLOAT,\n",
    "        Salinity FLOAT,\n",
    "        QF_4 FLOAT,\n",
    "        Sigma_theta FLOAT,\n",
    "        QF_5 FLOAT,\n",
    "        Depth FLOAT,\n",
    "        QF_6 FLOAT,\n",
    "        Oxygen FLOAT,\n",
    "        QF_7 FLOAT,\n",
    "        OxygenSat FLOAT,\n",
    "        QF_8 FLOAT,\n",
    "        Nitrate FLOAT,\n",
    "        QF_9 FLOAT,\n",
    "        Chl_a FLOAT,\n",
    "        QF_10 FLOAT,\n",
    "        b_bp700 FLOAT,\n",
    "        QF_11 FLOAT,\n",
    "        pHinsitu FLOAT,\n",
    "        QF_12 FLOAT,\n",
    "        b_bp532 FLOAT,\n",
    "        QF_13 FLOAT,\n",
    "        CDOM FLOAT,\n",
    "        QF_14 FLOAT,\n",
    "        TALK_CANYONB FLOAT,\n",
    "        QF_15 FLOAT,\n",
    "        DIC_CANYONB FLOAT,\n",
    "        QF_16 FLOAT,\n",
    "        pCO2_CANYONB FLOAT,\n",
    "        QF_17 FLOAT,\n",
    "        SAT_AR_CANYONB FLOAT,\n",
    "        QF_18 FLOAT,\n",
    "        pH25C_1atm FLOAT,\n",
    "        QF_19 FLOAT,\n",
    "        DOWNWELL_PAR FLOAT,\n",
    "        QF_20 FLOAT,\n",
    "        DOWN_IRRAD380 FLOAT,\n",
    "        QF_21 FLOAT,\n",
    "        DOWN_IRRAD443 FLOAT,\n",
    "        QF_22 FLOAT,\n",
    "        DOWN_IRRAD490 FLOAT,\n",
    "        QF_23 FLOAT,\n",
    "        VRS FLOAT,\n",
    "        QF_24 FLOAT,\n",
    "        VRS_STD FLOAT,\n",
    "        QF_25 FLOAT,\n",
    "        VK FLOAT,\n",
    "        QF_26 FLOAT,\n",
    "        VK_STD FLOAT,\n",
    "        QF_27 FLOAT,\n",
    "        IK FLOAT,\n",
    "        QF_28 FLOAT,\n",
    "        Ib FLOAT,\n",
    "        QF_29 FLOAT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TXT file\n",
    "file_path = r\"C:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\TestApp\\25202901RT.txt\"\n",
    "df = pd.read_csv(file_path, delimiter=\"\\t\", skiprows=6)  # Ensure delimiter matches your file format\n",
    "\n",
    "# Replace '-1e10' with NULL (None in Python) for missing values\n",
    "df.replace(-1e10, None, inplace=True)\n",
    "\n",
    "# Convert date column and store as string in 'YYYY-MM-DD' format\n",
    "df.insert(4, \"Date\", pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date)\n",
    "df['Date'] = df['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))  # Convert date to string format 'YYYY-MM-DD'\n",
    "\n",
    "# Convert time column and store as string in 'HH:MM:SS' format\n",
    "df.insert(5, \"Time\", pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time)\n",
    "df['Time'] = df['Time'].apply(lambda x: x.strftime('%H:%M:%S'))  # Convert time to string format 'HH:MM:SS'\n",
    "\n",
    "# Now, 'Date' and 'Time' columns are ready to be inserted into PostgreSQL\n",
    "\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date\n",
    "# df[\"Time\"] = pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time\n",
    "\n",
    "# Drop original date/time columns\n",
    "df.drop(columns=[\"mon/day/yr\", \"hh:mm\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     13\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(row\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))  \u001b[38;5;66;03m# Convert all data to string before insertion\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;43m        INSERT INTO oceanographic_data VALUES (\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Dynamically format placeholders\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Commit and close\u001b[39;00m\n\u001b[0;32m     19\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# PostgreSQL connection settings\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure each row is properly formatted as a tuple\n",
    "for _, row in df.iterrows():\n",
    "    values = tuple(row.astype(str))  # Convert all data to string before insertion\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO oceanographic_data VALUES ({})\n",
    "    \"\"\".format(\",\".join([\"%s\"] * len(values))), values)  # Dynamically format placeholders\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS ONE BELOW WORKS!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TXT file\n",
    "# file_path = r\"C:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\TestApp\\25202901RT.txt\"\n",
    "file_path = r\"\\\\atlas.shore.mbari.org\\ProjectLibrary\\901805_Coastal_Biogeochemical_Sensing\\Spray_Data\\24A03401\\24A03401RT.txt\"\n",
    "df = pd.read_csv(file_path, delimiter=\"\\t\", skiprows=6)  # Ensure delimiter matches your file format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = \"postgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\"\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are options to modify data before inserting into table.\n",
    "\n",
    "# Replace '-1e10' with NULL (None in Python) for missing values\n",
    "df.replace(-1e10, None, inplace=True)\n",
    "# df['Date'] = pd.to_datetime(df['mon/day/yr'], format='%m/%d/%Y')\n",
    "# df['Datetime'] = pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "\n",
    "\n",
    "# Convert date column and store as string in 'YYYY-MM-DD' format\n",
    "df.insert(4, \"Date\", pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date)\n",
    "df['Date'] = df['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))  # Convert date to string format 'YYYY-MM-DD'\n",
    "\n",
    "# Convert time column and store as string in 'HH:MM:SS' format\n",
    "df.insert(5, \"Time\", pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time)\n",
    "df['Time'] = df['Time'].apply(lambda x: x.strftime('%H:%M:%S'))  # Convert time to string format 'HH:MM:SS'\n",
    "\n",
    "# Convert time column and store as string in 'HH:MM:SS' format\n",
    "df.insert(6, \"Datetime\", pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M'))\n",
    "# df['TimDatetimee'] = df['Datetime'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))  # Convert time to string format 'HH:MM:SS'\n",
    "# df['PHIN_CANB_DELTA'] = df['pHinsitu[Total]'] - df['PHIN_CANYONB[Total]']\n",
    "# Now, 'Date' and 'Time' columns are ready to be inserted into PostgreSQL\n",
    "\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date\n",
    "# df[\"Time\"] = pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time\n",
    "\n",
    "# Drop original date/time columns\n",
    "df.drop(columns=[\"mon/day/yr\", \"hh:mm\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(df['Station'] > 50) & (df['Station'] < 100)] # reduce size for free db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a way more efficient solution\n",
    "df_existing = pd.read_sql('SELECT * FROM \"RT24A03401\"', engine) \n",
    "# Append new rows instead of rewriting the entire table\n",
    "# Filter only new rows\n",
    "new_rows = df[~df[\"unique_col\"].isin(df_existing[\"unique_col\"])]\n",
    "\n",
    "# Append only new rows\n",
    "new_rows.to_sql(\"RT25202901\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('RT24A03401', engine, if_exists='replace', index=False) # To upload all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cruise  Station Type        Date      Time            Datetime  \\\n",
      "0     24A03401        1    C  2024-10-22  17:58:00 2024-10-22 17:58:00   \n",
      "1     24A03401        1    C  2024-10-22  17:58:00 2024-10-22 17:58:00   \n",
      "2     24A03401        1    C  2024-10-22  17:58:00 2024-10-22 17:58:00   \n",
      "3     24A03401        1    C  2024-10-22  17:58:00 2024-10-22 17:58:00   \n",
      "4     24A03401        1    C  2024-10-22  17:58:00 2024-10-22 17:58:00   \n",
      "...        ...      ...  ...         ...       ...                 ...   \n",
      "6926  24A03401       63    C  2024-10-31  14:51:00 2024-10-31 14:51:00   \n",
      "6927  24A03401       63    C  2024-10-31  14:51:00 2024-10-31 14:51:00   \n",
      "6928  24A03401       63    C  2024-10-31  14:51:00 2024-10-31 14:51:00   \n",
      "6929  24A03401       63    C  2024-10-31  14:51:00 2024-10-31 14:51:00   \n",
      "6930  24A03401       63    C  2024-10-31  14:51:00 2024-10-31 14:51:00   \n",
      "\n",
      "      Lon [°E]  Lat [°N]  QF  Pressure[dbar]  ...  VK[Volts]  QF.25  \\\n",
      "0     -121.919    36.793   0           59.44  ...     3.9527    0.0   \n",
      "1     -121.919    36.793   0           58.24  ...     3.9527    0.0   \n",
      "2     -121.919    36.793   0           55.88  ...     3.9527    0.0   \n",
      "3     -121.919    36.793   0           54.16  ...     3.9527    0.0   \n",
      "4     -121.919    36.793   0           52.56  ...     3.9527    0.0   \n",
      "...        ...       ...  ..             ...  ...        ...    ...   \n",
      "6926  -122.028    36.767   0           13.20  ...     3.9527    0.0   \n",
      "6927  -122.028    36.767   0            9.40  ...     3.9527    0.0   \n",
      "6928  -122.028    36.767   0            4.84  ...     3.9527    0.0   \n",
      "6929  -122.028    36.767   0            0.92  ...     3.9527    0.0   \n",
      "6930  -122.028    36.767   0             NaN  ...        NaN    NaN   \n",
      "\n",
      "      VK_STD[Volts]  QF.26  IK[nA]  QF.27  Ib[nA]  QF.28  PHIN_CANYONB[Total]  \\\n",
      "0            3.9527    0.0  -13.33    0.0    -9.0    0.0               7.7279   \n",
      "1            3.9527    0.0  -13.33    0.0    -9.0    0.0               7.7282   \n",
      "2            3.9527    0.0  -13.33    0.0    -9.0    0.0               7.7292   \n",
      "3            3.9527    0.0  -13.33    0.0    -9.0    0.0               7.7328   \n",
      "4            3.9527    0.0  -13.33    0.0    -9.0    0.0               7.7359   \n",
      "...             ...    ...     ...    ...     ...    ...                  ...   \n",
      "6926         3.9527    0.0  -13.33    0.0    -9.0    0.0               7.8773   \n",
      "6927         3.9527    0.0  -13.33    0.0    -9.0    0.0               7.8981   \n",
      "6928         3.9527    0.0  -13.33    0.0    -9.0    0.0               7.9252   \n",
      "6929         3.9527    0.0  -13.33    0.0    -9.0    0.0               7.9861   \n",
      "6930            NaN    NaN     NaN    NaN     NaN    NaN                  NaN   \n",
      "\n",
      "      QF.29  \n",
      "0       8.0  \n",
      "1       8.0  \n",
      "2       8.0  \n",
      "3       8.0  \n",
      "4       8.0  \n",
      "...     ...  \n",
      "6926    0.0  \n",
      "6927    0.0  \n",
      "6928    0.0  \n",
      "6929    0.0  \n",
      "6930    NaN  \n",
      "\n",
      "[6931 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the 'data' table into a DataFrame\n",
    "# df = pd.read_sql(\"SELECT * FROM data\", engine)\n",
    "df = pd.read_sql('SELECT * FROM \"RT24A03401\"', engine) #double quotes needed for case-sensitive or numeric names\n",
    "\n",
    "# Display the first few rows\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use in app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedTable) relation \"data\" does not exist\nLINE 1: SELECT * FROM data\n                      ^\n\n[SQL: SELECT * FROM data]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedTable\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:942\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUndefinedTable\u001b[39m: relation \"data\" does not exist\nLINE 1: SELECT * FROM data\n                      ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m engine = create_engine(db_url)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Call to load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT * FROM data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:734\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    724\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.read_table(\n\u001b[32m    725\u001b[39m         sql,\n\u001b[32m    726\u001b[39m         index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    731\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    732\u001b[39m     )\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:1836\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   1780\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1781\u001b[39m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1788\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1789\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m   1790\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1791\u001b[39m \u001b[33;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1792\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1834\u001b[39m \n\u001b[32m   1835\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1836\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1837\u001b[39m     columns = result.keys()\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:1659\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   1657\u001b[39m args = [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[32m   1658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1659\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.con.execute(sql, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1776\u001b[39m, in \u001b[36mConnection.exec_driver_sql\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1771\u001b[39m execution_options = \u001b[38;5;28mself\u001b[39m._execution_options.merge_with(\n\u001b[32m   1772\u001b[39m     execution_options\n\u001b[32m   1773\u001b[39m )\n\u001b[32m   1775\u001b[39m dialect = \u001b[38;5;28mself\u001b[39m.dialect\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1980\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2351\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1962\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1969\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1970\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1971\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1975\u001b[39m         context.executemany,\n\u001b[32m   1976\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:942\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.UndefinedTable) relation \"data\" does not exist\nLINE 1: SELECT * FROM data\n                      ^\n\n[SQL: SELECT * FROM data]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# When app initializes\n",
    "db_url = \"postgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Call to load data\n",
    "df = pd.read_sql(\"SELECT * FROM data\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT25202901', 'RT24802901', 'RT24A03401']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import text\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "print(table_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table \"oceanographic_data\" dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "table_name = '\"oceanographic_data\"'  # Ensure the table name is correctly quoted\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'DROP TABLE IF EXISTS {table_name}'))\n",
    "    conn.commit()\n",
    "\n",
    "print(f\"Table {table_name} dropped successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import inspect\n",
    "db_url = \"postgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\"\n",
    "engine = create_engine(db_url)\n",
    "inspector = inspect(engine)\n",
    "files = inspector.get_table_names()\n",
    "latest_table = f'\"{files[-1]}\"'  # Add double quotes for case-sensitive or numeric table names\n",
    "query = f'SELECT * FROM {latest_table}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cruise  Station Type        Date      Time            Datetime  Lon [°E]  \\\n",
      "0  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "1  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "2  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "3  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "4  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "\n",
      "   Lat [°N]  QF  Pressure[dbar]  ...  VK[Volts]  QF.25  VK_STD[Volts]  QF.26  \\\n",
      "0    36.805   0           60.72  ...     0.3645    0.0            0.0    0.0   \n",
      "1    36.805   0           60.28  ...     0.3644    0.0            0.0    0.0   \n",
      "2    36.805   0           59.68  ...     0.3642    0.0            0.0    0.0   \n",
      "3    36.805   0           59.16  ...     0.3640    0.0            0.0    0.0   \n",
      "4    36.805   0           58.56  ...     0.3639    0.0            0.0    0.0   \n",
      "\n",
      "   IK[nA]  QF.27  Ib[nA]  QF.28  PHIN_CANYONB[Total]  QF.29  \n",
      "0  -13.33    0.0   187.9    0.0               7.9531    8.0  \n",
      "1  -13.33    0.0   187.8    0.0               7.9534    8.0  \n",
      "2  -20.00    0.0   187.8    0.0               7.9535    8.0  \n",
      "3   -6.67    0.0   187.8    0.0               7.9533    8.0  \n",
      "4  -13.33    0.0   187.7    0.0               7.9536    8.0  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, engine) #double quotes needed for case-sensitive or numeric names\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19402901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19402901SPRAY_RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19502901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19502902RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19702901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19A02901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/19C02902RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20202901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20702901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20703401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20903401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20A02901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20A03401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/20C02901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/21202901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/21303401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/21403401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/21503401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/21603401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/21903401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/22303401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/22602901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/22603401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/22902901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/22B03401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/23202901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/23303401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/23702901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/23803401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/23C02901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/23C02902RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/24403401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/24802901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/24A03401RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/25202901RT.txt', '/lobo/Data/GliderVizData//lobo/Data/GliderVizData/25420901RT.txt']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://sirocco/lobo/Data/GliderVizData/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get filenames only\n",
    "files = [a['href'] for a in soup.find_all('a', href=True) if 'RT.txt' in a['href']]\n",
    "print(files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"http://sirocco/lobo/Data/GliderVizData/\"\n",
    "\n",
    "response = requests.get(folder_path)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get clean filenames without path or extension\n",
    "# Get just the filename with extension (no path)\n",
    "files = [\n",
    "    os.path.basename(a['href'])\n",
    "    for a in soup.find_all('a', href=True)\n",
    "    if 'RT.txt' in a['href']\n",
    "]\n",
    "\n",
    "# Load and clean data\n",
    "def load_latest_data(folder_path, selected_file=None):\n",
    "    \"\"\"Loads the latest RT.txt file, cleans it, and returns a DataFrame.\"\"\"\n",
    "    # print(\"loading file\")\n",
    "    filename = selected_file if selected_file else files[-1]\n",
    "    file_url = folder_path + filename\n",
    "    file_response = requests.get(file_url)\n",
    "    file_content = StringIO(file_response.text)\n",
    "    df = pd.read_csv(file_content, delimiter=\"\\t\", skiprows=6)\n",
    "    \n",
    "    # Clean data\n",
    "    df.columns = df.columns.str.replace('Â', '') # Issue when importing from html\n",
    "    df.replace(-1e10, pd.NA, inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['mon/day/yr'], format='%m/%d/%Y')\n",
    "    df['Datetime'] = pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M')\n",
    "    # Only calculate pHin_Canb_Delta if 'PHIN_CANYONB[Total]' exists\n",
    "    if 'PHIN_CANYONB[Total]' in df.columns:\n",
    "        df['pHin_Canb_Delta'] = df['pHinsitu[Total]'] - df['PHIN_CANYONB[Total]']\n",
    "    else:\n",
    "        df['pHin_Canb_Delta'] = pd.NA  # Optional: Add the column as all-NA if needed    \n",
    "    \n",
    "    return df\n",
    "    # print(df[\"Station\"].head())\n",
    "df = load_latest_data(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      2\u001b[39m folder_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33msirocco\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mwwwroot\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mlobo\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mData\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mGliderVizData\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mRT.txt\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load and clean data\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 53] The network path was not found: '\\\\\\\\sirocco\\\\wwwroot\\\\lobo\\\\Data\\\\GliderVizData'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3567\u001b[39m, in \u001b[36mInteractiveShell.run_code\u001b[39m\u001b[34m(self, code_obj, result, async_)\u001b[39m\n\u001b[32m   3565\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   3566\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3567\u001b[39m         result.error_in_exec = \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   3568\u001b[39m     \u001b[38;5;28mself\u001b[39m.showtraceback(running_compiled_code=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3569\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Hardcode path to files and create list\n",
    "folder_path = r\"\\\\sirocco\\wwwroot\\lobo\\Data\\GliderVizData\"\n",
    "files = [f for f in os.listdir(folder_path) if 'RT.txt' in f]\n",
    "\n",
    "# Load and clean data\n",
    "def load_latest_data(folder_path, selected_file=None):\n",
    "    \"\"\"Loads the latest RT.txt file, cleans it, and returns a DataFrame.\"\"\"\n",
    "    # print(\"loading file\")\n",
    "    filename = os.path.join(folder_path, folder_path, selected_file if selected_file else files[-1])\n",
    "    df = pd.read_csv(filename, delimiter=\"\\t\", skiprows=6)\n",
    "\n",
    "    # Clean data\n",
    "    df.replace(-1e10, pd.NA, inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['mon/day/yr'], format='%m/%d/%Y')\n",
    "    df['Datetime'] = pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M')\n",
    "    # Only calculate pHin_Canb_Delta if 'PHIN_CANYONB[Total]' exists\n",
    "    if 'PHIN_CANYONB[Total]' in df.columns:\n",
    "        df['pHin_Canb_Delta'] = df['pHinsitu[Total]'] - df['PHIN_CANYONB[Total]']\n",
    "    else:\n",
    "        df['pHin_Canb_Delta'] = pd.NA  # Optional: Add the column as all-NA if needed    \n",
    "    \n",
    "    return df\n",
    "    # print(df[\"Station\"].head())\n",
    "df = load_latest_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     latitude  longitude\n",
      "0        25.1      -80.2\n",
      "1        25.2      -80.2\n",
      "2        25.3      -80.2\n",
      "3        25.4      -80.1\n",
      "4        25.5      -80.1\n",
      "..        ...        ...\n",
      "613      28.2      -78.9\n",
      "614      28.1      -78.9\n",
      "615      28.0      -78.8\n",
      "616      27.9      -78.7\n",
      "617      27.8      -78.6\n",
      "\n",
      "[618 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Retrieve the data\n",
    "url = 'https://ocean.weather.gov/gulf_stream_latest.txt'\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "# Step 2: Locate the coordinates section\n",
    "match = re.search(r'RMKS/1\\. GULF STREAM NORTH WALL DATA FOR.*?:\\s*(.*?)(?:RMKS/|$)', data, re.S)\n",
    "if not match:\n",
    "    raise ValueError('Could not locate the Gulf Stream coordinates section.')\n",
    "coordinates_text = match.group(1).strip()\n",
    "\n",
    "# Step 3: Extract coordinate pairs (format like 25.5N80.1W)\n",
    "coordinate_strings = re.findall(r'(\\d+\\.\\d+N\\d+\\.\\d+W)', coordinates_text)\n",
    "\n",
    "# Step 4: Convert to decimal degrees and store in lists\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for pair in coordinate_strings:\n",
    "    lat_str, lon_str = re.match(r'(\\d+\\.\\d+)N(\\d+\\.\\d+)W', pair).groups()\n",
    "    latitudes.append(float(lat_str))\n",
    "    longitudes.append(-float(lon_str))  # W longitude is negative\n",
    "\n",
    "# Step 5: Create a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Lat': latitudes,\n",
    "    'Lon': longitudes\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash_bootstrap_components as dbc\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input, State\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "# Hardcode path to files and create list of all missions\n",
    "folder_path = \"https://www3.mbari.org/lobo/Data/GliderVizData/\"\n",
    "\n",
    "response = requests.get(folder_path)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get clean filenames without path or extension\n",
    "# Get just the filename with extension (no path)\n",
    "files = [\n",
    "    os.path.basename(a['href'])\n",
    "    for a in soup.find_all('a', href=True)\n",
    "    if 'RT.txt' in a['href']\n",
    "]\n",
    "\n",
    "# Load and clean data\n",
    "def load_latest_data(folder_path, selected_file=None):\n",
    "    \"\"\"Loads the latest RT.txt file, cleans it, and returns a DataFrame.\"\"\"\n",
    "    filename = selected_file if selected_file else files[-1]\n",
    "    file_url = folder_path + filename\n",
    "    file_response = requests.get(file_url)\n",
    "    file_content = StringIO(file_response.text)\n",
    "    df = pd.read_csv(file_content, delimiter=\"\\t\", skiprows=6)\n",
    "\n",
    "    # Clean data\n",
    "    df.columns = df.columns.str.replace('Â', '') # Issue when importing from html\n",
    "    df.replace(-1e10, pd.NA, inplace=True)\n",
    "    df.replace(-999, pd.NA, inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['mon/day/yr'], format='%m/%d/%Y')\n",
    "    df['Datetime'] = pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M')\n",
    "    # Only calculate pHin_Canb_Delta if 'PHIN_CANYONB[Total]' exists\n",
    "    if 'PHIN_CANYONB[Total]' in df.columns:\n",
    "        df['pHin_Canb_Delta'] = df['pHinsitu[Total]'] - df['PHIN_CANYONB[Total]']\n",
    "    else:\n",
    "        df['pHin_Canb_Delta'] = pd.NA  # Optional: Add the column as all-NA if needed     \n",
    "    return df\n",
    "\n",
    "df = load_latest_data(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
