{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection parameters (replace with your own Render database details)\n",
    "host = \"dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com\"  # Use your Render PostgreSQL hostname\n",
    "database = \"spraydabase\"\n",
    "user = \"spraydabase_user\"\n",
    "password = \"8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ\"\n",
    "port = 5432\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(dbname=database, user=user, password=password, host=host, port=port)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table if it doesn't exist\n",
    "cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS oceanographic_data;\n",
    "               \n",
    "    CREATE TABLE oceanographic_data (\n",
    "        Cruise VARCHAR,\n",
    "        Station INT,\n",
    "        Type VARCHAR(1),\n",
    "        Date VARCHAR,\n",
    "        Time VARCHAR,\n",
    "        Datetime VARCHAR,\n",
    "        Lon FLOAT,\n",
    "        Lat FLOAT,\n",
    "        QF_1 FLOAT,\n",
    "        Pressure FLOAT,\n",
    "        QF_2 FLOAT,\n",
    "        Temperature FLOAT,\n",
    "        QF_3 FLOAT,\n",
    "        Salinity FLOAT,\n",
    "        QF_4 FLOAT,\n",
    "        Sigma_theta FLOAT,\n",
    "        QF_5 FLOAT,\n",
    "        Depth FLOAT,\n",
    "        QF_6 FLOAT,\n",
    "        Oxygen FLOAT,\n",
    "        QF_7 FLOAT,\n",
    "        OxygenSat FLOAT,\n",
    "        QF_8 FLOAT,\n",
    "        Nitrate FLOAT,\n",
    "        QF_9 FLOAT,\n",
    "        Chl_a FLOAT,\n",
    "        QF_10 FLOAT,\n",
    "        b_bp700 FLOAT,\n",
    "        QF_11 FLOAT,\n",
    "        pHinsitu FLOAT,\n",
    "        QF_12 FLOAT,\n",
    "        b_bp532 FLOAT,\n",
    "        QF_13 FLOAT,\n",
    "        CDOM FLOAT,\n",
    "        QF_14 FLOAT,\n",
    "        TALK_CANYONB FLOAT,\n",
    "        QF_15 FLOAT,\n",
    "        DIC_CANYONB FLOAT,\n",
    "        QF_16 FLOAT,\n",
    "        pCO2_CANYONB FLOAT,\n",
    "        QF_17 FLOAT,\n",
    "        SAT_AR_CANYONB FLOAT,\n",
    "        QF_18 FLOAT,\n",
    "        pH25C_1atm FLOAT,\n",
    "        QF_19 FLOAT,\n",
    "        DOWNWELL_PAR FLOAT,\n",
    "        QF_20 FLOAT,\n",
    "        DOWN_IRRAD380 FLOAT,\n",
    "        QF_21 FLOAT,\n",
    "        DOWN_IRRAD443 FLOAT,\n",
    "        QF_22 FLOAT,\n",
    "        DOWN_IRRAD490 FLOAT,\n",
    "        QF_23 FLOAT,\n",
    "        VRS FLOAT,\n",
    "        QF_24 FLOAT,\n",
    "        VRS_STD FLOAT,\n",
    "        QF_25 FLOAT,\n",
    "        VK FLOAT,\n",
    "        QF_26 FLOAT,\n",
    "        VK_STD FLOAT,\n",
    "        QF_27 FLOAT,\n",
    "        IK FLOAT,\n",
    "        QF_28 FLOAT,\n",
    "        Ib FLOAT,\n",
    "        QF_29 FLOAT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TXT file\n",
    "file_path = r\"C:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\TestApp\\25202901RT.txt\"\n",
    "df = pd.read_csv(file_path, delimiter=\"\\t\", skiprows=6)  # Ensure delimiter matches your file format\n",
    "\n",
    "# Replace '-1e10' with NULL (None in Python) for missing values\n",
    "df.replace(-1e10, None, inplace=True)\n",
    "\n",
    "# Convert date column and store as string in 'YYYY-MM-DD' format\n",
    "df.insert(4, \"Date\", pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date)\n",
    "df['Date'] = df['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))  # Convert date to string format 'YYYY-MM-DD'\n",
    "\n",
    "# Convert time column and store as string in 'HH:MM:SS' format\n",
    "df.insert(5, \"Time\", pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time)\n",
    "df['Time'] = df['Time'].apply(lambda x: x.strftime('%H:%M:%S'))  # Convert time to string format 'HH:MM:SS'\n",
    "\n",
    "# Now, 'Date' and 'Time' columns are ready to be inserted into PostgreSQL\n",
    "\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date\n",
    "# df[\"Time\"] = pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time\n",
    "\n",
    "# Drop original date/time columns\n",
    "df.drop(columns=[\"mon/day/yr\", \"hh:mm\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     13\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(row\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))  \u001b[38;5;66;03m# Convert all data to string before insertion\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;43m        INSERT INTO oceanographic_data VALUES (\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Dynamically format placeholders\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Commit and close\u001b[39;00m\n\u001b[0;32m     19\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# PostgreSQL connection settings\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure each row is properly formatted as a tuple\n",
    "for _, row in df.iterrows():\n",
    "    values = tuple(row.astype(str))  # Convert all data to string before insertion\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO oceanographic_data VALUES ({})\n",
    "    \"\"\".format(\",\".join([\"%s\"] * len(values))), values)  # Dynamically format placeholders\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS ONE BELOW WORKS!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TXT file\n",
    "# file_path = r\"C:\\Users\\bwerb\\Documents\\GitHub\\PlotlyDashApps\\TestApp\\25202901RT.txt\"\n",
    "file_path = r\"\\\\atlas.shore.mbari.org\\ProjectLibrary\\901805_Coastal_Biogeochemical_Sensing\\Spray_Data\\25202901\\25202901RT.txt\"\n",
    "df = pd.read_csv(file_path, delimiter=\"\\t\", skiprows=6)  # Ensure delimiter matches your file format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = \"postgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\"\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are options to modify data before inserting into table.\n",
    "\n",
    "# Replace '-1e10' with NULL (None in Python) for missing values\n",
    "df.replace(-1e10, None, inplace=True)\n",
    "# df['Date'] = pd.to_datetime(df['mon/day/yr'], format='%m/%d/%Y')\n",
    "# df['Datetime'] = pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "\n",
    "\n",
    "# Convert date column and store as string in 'YYYY-MM-DD' format\n",
    "df.insert(4, \"Date\", pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date)\n",
    "df['Date'] = df['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))  # Convert date to string format 'YYYY-MM-DD'\n",
    "\n",
    "# Convert time column and store as string in 'HH:MM:SS' format\n",
    "df.insert(5, \"Time\", pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time)\n",
    "df['Time'] = df['Time'].apply(lambda x: x.strftime('%H:%M:%S'))  # Convert time to string format 'HH:MM:SS'\n",
    "\n",
    "# Convert time column and store as string in 'HH:MM:SS' format\n",
    "df.insert(6, \"Datetime\", pd.to_datetime(df['mon/day/yr'] + ' ' + df['hh:mm'], format='%m/%d/%Y %H:%M'))\n",
    "# df['TimDatetimee'] = df['Datetime'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))  # Convert time to string format 'HH:MM:SS'\n",
    "df['PHIN_CANB_DELTA'] = df['pHinsitu[Total]'] - df['PHIN_CANYONB[Total]']\n",
    "# Now, 'Date' and 'Time' columns are ready to be inserted into PostgreSQL\n",
    "\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"mon/day/yr\"], format=\"%m/%d/%Y\").dt.date\n",
    "# df[\"Time\"] = pd.to_datetime(df[\"hh:mm\"], format=\"%H:%M\").dt.time\n",
    "\n",
    "# Drop original date/time columns\n",
    "df.drop(columns=[\"mon/day/yr\", \"hh:mm\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a way more efficient solution\n",
    "df_existing = pd.read_sql('SELECT * FROM \"RT25202901\"', engine) \n",
    "# Append new rows instead of rewriting the entire table\n",
    "# Filter only new rows\n",
    "new_rows = df[~df[\"unique_col\"].isin(df_existing[\"unique_col\"])]\n",
    "\n",
    "# Append only new rows\n",
    "new_rows.to_sql(\"RT25202901\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('RT25202901', engine, if_exists='replace', index=False) # To upload all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Cruise  Station Type        Date      Time            Datetime  \\\n",
      "0      25202901      223    C  2025-02-28  08:51:00 2025-02-28 08:51:00   \n",
      "1      25202901      223    C  2025-02-28  08:51:00 2025-02-28 08:51:00   \n",
      "2      25202901      223    C  2025-02-28  08:51:00 2025-02-28 08:51:00   \n",
      "3      25202901      223    C  2025-02-28  08:51:00 2025-02-28 08:51:00   \n",
      "4      25202901      223    C  2025-02-28  08:51:00 2025-02-28 08:51:00   \n",
      "...         ...      ...  ...         ...       ...                 ...   \n",
      "39594  25202901      222    C  2025-02-28  06:10:00 2025-02-28 06:10:00   \n",
      "39595  25202901      222    C  2025-02-28  06:10:00 2025-02-28 06:10:00   \n",
      "39596  25202901      222    C  2025-02-28  06:10:00 2025-02-28 06:10:00   \n",
      "39597  25202901      222    C  2025-02-28  06:10:00 2025-02-28 06:10:00   \n",
      "39598  25202901      223    C  2025-02-28  08:51:00 2025-02-28 08:51:00   \n",
      "\n",
      "       Lon [째E]  Lat [째N]  QF  Pressure[dbar]  ...  QF.25  VK_STD[Volts]  \\\n",
      "0      -122.103    36.728   0          509.56  ...    0.0            0.0   \n",
      "1      -122.103    36.728   0          508.20  ...    0.0            0.0   \n",
      "2      -122.103    36.728   0          506.72  ...    0.0            0.0   \n",
      "3      -122.103    36.728   0          505.00  ...    0.0            0.0   \n",
      "4      -122.103    36.728   0          502.84  ...    0.0            0.0   \n",
      "...         ...       ...  ..             ...  ...    ...            ...   \n",
      "39594  -122.106    36.699   0            6.20  ...    0.0            0.0   \n",
      "39595  -122.106    36.699   0            3.80  ...    0.0            0.0   \n",
      "39596  -122.106    36.699   0            1.84  ...    0.0            0.0   \n",
      "39597  -122.106    36.699   0             NaN  ...    NaN            NaN   \n",
      "39598  -122.103    36.728   0          510.76  ...    0.0            0.0   \n",
      "\n",
      "       QF.26  IK[nA]  QF.27  Ib[nA]  QF.28  PHIN_CANYONB[Total]  QF.29  \\\n",
      "0        0.0  273.33    0.0   187.0    0.0               7.5141    8.0   \n",
      "1        0.0  273.33    0.0   187.0    0.0               7.5144    8.0   \n",
      "2        0.0  273.33    0.0   187.0    0.0               7.5126    8.0   \n",
      "3        0.0  273.33    0.0   187.0    0.0               7.5137    8.0   \n",
      "4        0.0  280.00    0.0   187.0    0.0               7.5142    8.0   \n",
      "...      ...     ...    ...     ...    ...                  ...    ...   \n",
      "39594    0.0  326.67    0.0   187.6    0.0               7.8131    0.0   \n",
      "39595    0.0  326.67    0.0   187.6    0.0               7.8314    0.0   \n",
      "39596    0.0  320.00    0.0   187.6    0.0               7.8478    0.0   \n",
      "39597    NaN     NaN    NaN     NaN    NaN                  NaN    NaN   \n",
      "39598    0.0  273.33    0.0   187.0    0.0               7.5136    8.0   \n",
      "\n",
      "       PHIN_CANB_DELTA  \n",
      "0               0.0221  \n",
      "1               0.0219  \n",
      "2               0.0233  \n",
      "3               0.0222  \n",
      "4               0.0217  \n",
      "...                ...  \n",
      "39594           0.0591  \n",
      "39595           0.0529  \n",
      "39596           0.0429  \n",
      "39597              NaN  \n",
      "39598           0.0226  \n",
      "\n",
      "[39599 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the 'data' table into a DataFrame\n",
    "# df = pd.read_sql(\"SELECT * FROM data\", engine)\n",
    "df = pd.read_sql('SELECT * FROM \"RT25202901\"', engine) #double quotes needed for case-sensitive or numeric names\n",
    "\n",
    "# Display the first few rows\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use in app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# When app initializes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m db_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m(db_url)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Call to load data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM data\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# When app initializes\n",
    "db_url = \"postgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Call to load data\n",
    "df = pd.read_sql(\"SELECT * FROM data\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT25202901']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import text\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "print(table_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table \"oceanographic_data\" dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "table_name = '\"oceanographic_data\"'  # Ensure the table name is correctly quoted\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'DROP TABLE IF EXISTS {table_name}'))\n",
    "    conn.commit()\n",
    "\n",
    "print(f\"Table {table_name} dropped successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import inspect\n",
    "db_url = \"postgresql://spraydabase_user:8pgy9Sba79ETgds8QcaycQj0U6uIhhwQ@dpg-cur2o7lds78s7384jthg-a.oregon-postgres.render.com/spraydabase\"\n",
    "engine = create_engine(db_url)\n",
    "inspector = inspect(engine)\n",
    "files = inspector.get_table_names()\n",
    "latest_table = f'\"{files[-1]}\"'  # Add double quotes for case-sensitive or numeric table names\n",
    "query = f'SELECT * FROM {latest_table}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cruise  Station Type        Date      Time            Datetime  Lon [째E]  \\\n",
      "0  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "1  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "2  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "3  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "4  25202901        1    C  2025-02-05  16:59:00 2025-02-05 16:59:00  -121.859   \n",
      "\n",
      "   Lat [째N]  QF  Pressure[dbar]  ...  VK[Volts]  QF.25  VK_STD[Volts]  QF.26  \\\n",
      "0    36.805   0           60.72  ...     0.3645    0.0            0.0    0.0   \n",
      "1    36.805   0           60.28  ...     0.3644    0.0            0.0    0.0   \n",
      "2    36.805   0           59.68  ...     0.3642    0.0            0.0    0.0   \n",
      "3    36.805   0           59.16  ...     0.3640    0.0            0.0    0.0   \n",
      "4    36.805   0           58.56  ...     0.3639    0.0            0.0    0.0   \n",
      "\n",
      "   IK[nA]  QF.27  Ib[nA]  QF.28  PHIN_CANYONB[Total]  QF.29  \n",
      "0  -13.33    0.0   187.9    0.0               7.9531    8.0  \n",
      "1  -13.33    0.0   187.8    0.0               7.9534    8.0  \n",
      "2  -20.00    0.0   187.8    0.0               7.9535    8.0  \n",
      "3   -6.67    0.0   187.8    0.0               7.9533    8.0  \n",
      "4  -13.33    0.0   187.7    0.0               7.9536    8.0  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, engine) #double quotes needed for case-sensitive or numeric names\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
